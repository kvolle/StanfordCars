{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5661df3d-b104-4ef3-b024-9f5f77feaf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#needed for evaluation metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import pandas as pd\n",
    "\n",
    "#needed for calibration metrics\n",
    "from sklearn.calibration import calibration_curve\n",
    "from torchmetrics.classification import MulticlassCalibrationError\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "#new loss\n",
    "from calibratedclassification.DominoLoss import DOMINO_Loss\n",
    "from calibratedclassification.DominoLossW import DOMINO_Loss_W\n",
    "\n",
    "from calibratedclassification.reliability_diagrams import *\n",
    "\n",
    "import random\n",
    "random.seed(1)\n",
    "random_seed = random.seed(1)\n",
    "\n",
    "from calibratedclassification.RCR import RCRMetric#, RCRMMetric\n",
    "\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1571ffa-b357-42a6-9915-d39725c111d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE_train = 100#500#\n",
    "BATCH_SIZE_test = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c672fe-9422-40d8-80b6-f3c88cd58e86",
   "metadata": {},
   "source": [
    "object_categories = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"]\n",
    "object_dict = {}\n",
    "for o in range(len(object_categories)):\n",
    "    object_dict[object_categories[o]] = o\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.1307,])\n",
    "    std = np.array([0.3081,])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    fig = plt.figure(figsize=(200., 200.))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2fc5d1f-db57-45a3-8df0-d4dcbf72a633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images training: 8144\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 96\u001b[0m\n\u001b[1;32m     77\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m val_loader\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#test_loader = torch.utils.data.DataLoader(ball_data(test_dir)[0], batch_size=BATCH_SIZE, shuffle=True)\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Iterate through the DataLoader only once\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m#N_CLASSES = 18 #len(torch.unique(labels))\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m IMG_SIZE \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     97\u001b[0m IMG_CH \u001b[38;5;241m=\u001b[39m train[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mIMG_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CustomDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Define transformations to be applied to each image\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.RandomApply([transforms.RandomHorizontalFlip()], p=0.25),  # Apply with 50% probability\n",
    "    transforms.RandomApply([transforms.RandomRotation(15)], p=0.25),  # Apply with 50% probability\n",
    "    transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1)], p=0.25),  # Apply with 50% probability\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define the root directory of your dataset\n",
    "train_dir = '/home/kyle/Desktop/Misc/Datasets/StanfordCarsClassFolders/car_data/train/'\n",
    "valid_dir = '/home/kyle/Desktop/Misc/Datasets/StanfordCarsClassFolders/car_data/test/'\n",
    "#test_dir = '/blue/ruogu.fang/skylastolte4444/Airplanes/Diffusion/Data/cars/test/'\n",
    "\n",
    "# Extract class names from folder names\n",
    "#class_names = [folder_name for folder_name in os.listdir(data_dir) \n",
    "#               if os.path.isdir(os.path.join(data_dir, folder_name)) \n",
    "#               and not folder_name.endswith('.txt')]\n",
    "\n",
    "#class_names = []\n",
    "\n",
    "# Create a dataset from the CustomDataset class\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]\n",
    "\n",
    "def ball_data(data_dir):\n",
    "    class_names = []\n",
    "    folder_names = os.listdir(data_dir)\n",
    "    folder_names.sort()\n",
    "\n",
    "    for folder_name in folder_names:\n",
    "        full_path = os.path.join(data_dir, folder_name)\n",
    "        if os.path.isdir(full_path) and not os.path.isfile(full_path) and 'ipynb' not in folder_name:\n",
    "            class_names.append(folder_name)\n",
    "\n",
    "    # Filter out images containing \"inverted\" in their name\n",
    "    dataset_filtered = []\n",
    "    for class_name in class_names:\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        image_files = [file for file in os.listdir(class_dir) if file.endswith(('.png', '.jpg')) and \"inverted\" not in file]\n",
    "        class_images = [(os.path.join(class_dir, image_file), class_names.index(class_name)) for image_file in image_files]\n",
    "        dataset_filtered.extend(class_images)\n",
    "\n",
    "    # Define the number of augmented samples to be generated for each original image\n",
    "    num_augmented_samples = 1\n",
    "\n",
    "    # Apply augmentation to each original image and add to the dataset\n",
    "    dataset_augmented = []\n",
    "    for image_path, label in dataset_filtered:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        for _ in range(num_augmented_samples):\n",
    "            augmented_image = data_transform(image)\n",
    "            dataset_augmented.append((augmented_image, label))\n",
    "\n",
    "    # Create a dataset from the augmented list\n",
    "    dataset = CustomDataset(dataset_augmented)\n",
    "    return dataset, class_names\n",
    "\n",
    "print(f\"Number of images training: {len(ball_data(train_dir)[0])}\")\n",
    "\n",
    "# Define batch size\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "train = ball_data(train_dir)\n",
    "val = ball_data(valid_dir)\n",
    "\n",
    "# Create a DataLoader to load the data in batches\n",
    "train_loader = torch.utils.data.DataLoader(train[0], batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val[0], batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = val_loader\n",
    "#test_loader = torch.utils.data.DataLoader(ball_data(test_dir)[0], batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Iterate through the DataLoader only once\n",
    "#for batch in train_loader:\n",
    "#    images, labels = batch\n",
    "#    # Display a few sample images\n",
    "#    num_samples = 5\n",
    "#    fig, axes = plt.subplots(1, num_samples, figsize=(20, 5))\n",
    "#    for i in range(num_samples):\n",
    "#        image = images[i].permute(1, 2, 0).numpy()  # Convert tensor to numpy array and rearrange dimensions\n",
    "#        label = ball_data(train_dir)[1][labels[i]]  # Get the class label\n",
    "#        axes[i].imshow(image)\n",
    "#        axes[i].set_title(f'Label: {label}')\n",
    "#        axes[i].axis('off')\n",
    "#    plt.show()\n",
    "#    break  # Break after displaying one batch\n",
    "    \n",
    "#N_CLASSES = 18 #len(torch.unique(labels))\n",
    "IMG_SIZE = train[0].shape[2]\n",
    "IMG_CH = train[0].shape[1]\n",
    "\n",
    "print(f\"Image size: {IMG_SIZE}\")\n",
    "print(f\"Number of channels: {IMG_CH}\")\n",
    "\n",
    "class_names = train[1]\n",
    "\n",
    "#class_names = os.listdir(data_dir)\n",
    "N_CLASSES = len(np.unique(class_names))\n",
    "\n",
    "print(f\"Number of classes: {N_CLASSES}\")\n",
    "\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da6293f-d563-4bf1-a78c-4cdefd2681b6",
   "metadata": {},
   "source": [
    "class_names = ball_data(train_dir)[1]\n",
    "\n",
    "#class_names = os.listdir(data_dir)\n",
    "N_CLASSES = len(np.unique(class_names))\n",
    "\n",
    "print(f\"Number of classes: {N_CLASSES}\")\n",
    "\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24286580-1907-481b-a42a-3caeaa9cfc26",
   "metadata": {},
   "source": [
    "for i, data in enumerate(matrix_maker):\n",
    "  image, label = data\n",
    "  print(torch.unique(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf292e7-2f07-4792-91ff-e654aa927570",
   "metadata": {},
   "source": [
    "np.random.seed(42)\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "fig = plt.figure(1, figsize=(18, 16))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(5, 5), axes_pad=0.05)\n",
    "for i, data in enumerate(test_loader):\n",
    "  image, label = data\n",
    "\n",
    "images = image[0:25, :, :, :]\n",
    "labels = label[0:25]\n",
    "\n",
    "images = torch.transpose(images, 1, 3)\n",
    "images = torch.transpose(images, 1, 2)\n",
    "\n",
    "for i in range(25):\n",
    "\n",
    "  ax = grid[i]\n",
    "  ax.imshow(images[i,:,:,:])\n",
    "  ax.text(0, 32, 'Label: {}'.format(labels[i]), color='k', backgroundcolor='w', alpha=0.8)\n",
    "  ax.axis(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecc76a-b4cc-45cb-951d-2bc95dce4dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add directories for models and results\n",
    "\n",
    "#generic directories\n",
    "working_root = '/blue/ruogu.fang/skylastolte4444/Airplanes/SAR_for_Uncertainty-main/SAR_for_Uncertainty-main/'\n",
    "model_save_path = working_root + 'models_cars/'\n",
    "results_save_path = working_root + 'results_cars/'\n",
    "\n",
    "#specific model definitions\n",
    "model_name = 'resnet50_CE'#DOMINO-SSIM_REAL'\n",
    "DOMINO = False\n",
    "DOMINOW = False\n",
    "\n",
    "#specific model path\n",
    "results_model = results_save_path + model_name\n",
    "\n",
    "#make all non-existing directories\n",
    "isModelPath = os.path.exists(model_save_path)\n",
    "isResultsPath = os.path.exists(results_save_path)\n",
    "isModelResultsPath = os.path.exists(results_model)\n",
    "\n",
    "if not isModelPath:\n",
    "    os.mkdir(model_save_path)\n",
    "    \n",
    "if not isResultsPath:\n",
    "    os.mkdir(results_save_path)\n",
    "\n",
    "if not isModelResultsPath:\n",
    "    os.mkdir(results_model)\n",
    "\n",
    "#os.makedirs(results_save_path + model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f911a4-9e22-4308-819d-bcd34a6922e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOMINO or DOMINOW:\n",
    "    #matrix_dir = working_root + 'scripts/OxfordSubDir/' #matrix_penalties_pet/'#matrix_penalties_pet/'\n",
    "    matrix_dir = '/blue/ruogu.fang/skylastolte4444/Airplanes/Diffusion/'\n",
    "    #matrix_vals = pd.read_csv(matrix_dir + 'oxfordpets_ssim_matrix_norm4.csv', header = 0, index_col=0) #'Dictionary_matrixpenalty_inv_patches_v1_1024.csv', index_col = 0) #header=None\n",
    "    #matrix_vals = pd.read_csv(matrix_dir + 'hc_matrixpenalty.csv', index_col = None, header=None)\n",
    "    matrix_vals = pd.read_csv(matrix_dir + 'cars_s64_e100_t900.csv', index_col=0, header=0)\n",
    "    matrix_penalty = 3.0 * torch.from_numpy(matrix_vals.to_numpy())\n",
    "    matrix_penalty = matrix_penalty.float().cuda()\n",
    "    print(matrix_penalty.shape)\n",
    "    \n",
    "if DOMINO:\n",
    "    a = 0.5\n",
    "    b = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0a0fb6-dd8f-4846-ac15-d5dc4496927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a pre-trained model\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "#model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "#model.fc.out_features = len(object_categories)\n",
    "model.fc = nn.Linear(2048, len(class_names))\n",
    "#model.fc = nn.Linear(512, len(object_categories))\n",
    "\n",
    "#pretrained = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "#backbone = torch.nn.Sequential(*(list(pretrained.children())[:-1]))\n",
    "#model = torch.nn.Sequential(backbone, nn.Linear(2048, len(object_categories)))\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Specify Loss\n",
    "if DOMINO:\n",
    "    criterion = DOMINO_Loss()\n",
    "elif DOMINOW:\n",
    "    criterion = DOMINO_Loss_W()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    " # construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# let's train it for 1 epoch\n",
    "num_epochs = 50\n",
    "logging_freq = 147\n",
    "save_freq = 5\n",
    "\n",
    "# Get a batch of training data\n",
    "##inputs, classes = next(iter(train_loader))\n",
    "#inputs, classes = next(iter(dataloaders['train']))\n",
    "#print(inputs.shape)\n",
    "##inputs_min = inputs[0:32, :, :, :]\n",
    "# Make a grid from batch\n",
    "##out = torchvision.utils.make_grid(inputs_min)\n",
    "##imshow(out, title=[class_names[x] for x in classes])\n",
    "#plt.show()\n",
    "\n",
    "#print(\"Train size: %d Val size: %d\" % (train_size, valid_size))#dataset_sizes['train'], dataset_sizes['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a81fd6f-892c-4990-91f4-38cf69619412",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_best = 0\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.\n",
    "    correct = 0.\n",
    "    seen = 0.\n",
    "    val_correct = 0.\n",
    "    val_seen = 0.\n",
    "    logging_step = 1\n",
    "    \n",
    "    for i, data in enumerate(train_loader, 0):##dataloaders['train'], 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        bs, c, h, w = inputs.shape\n",
    "        if c == 1:\n",
    "            inputs = inputs.repeat(1, 3, 1, 1).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        #outputs = outputs.logits\n",
    "        if DOMINO:\n",
    "            loss = criterion(outputs, labels, matrix_penalty, a, b)\n",
    "        elif DOMINOW:\n",
    "            loss = criterion(outputs, labels, matrix_penalty, 1)\n",
    "        else:\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        correct += (outputs.argmax(dim=1) == labels).float().sum()\n",
    "        seen += len(labels)\n",
    "\n",
    "    for i, data in enumerate(val_loader, 0):##dataloaders['val'], 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        bs, c, h, w = inputs.shape\n",
    "        if c == 1:\n",
    "            inputs = inputs.repeat(1, 3, 1, 1).float()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "        val_correct += (outputs.argmax(dim=1) == labels).float().sum()\n",
    "        val_seen += len(labels)\n",
    "    \n",
    "    #changed to only save models when validation improves\n",
    "    val_acc = val_correct/val_seen\n",
    "    if val_acc>val_acc_best:\n",
    "        torch.save(model.state_dict(), model_save_path + model_name + '.pth')\n",
    "        val_acc_best=val_acc\n",
    "        print('The new best validation accuracy is %.4f, saving model' % (val_acc_best))\n",
    "\n",
    "    print(\"Epoch %d, loss: %.3f, Train acc: %.4f, Val acc: %.4f\" % (epoch + 1,  running_loss/seen, correct/seen, val_correct/val_seen))\n",
    " \n",
    "\n",
    "    #if (epoch +1) % save_freq == 0:\n",
    "    #    torch.save(model.state_dict(),'./models/checkpoint_%d.pth'%(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa54771-a53a-45ba-8d97-28c5ef4f893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload best model\n",
    "model.load_state_dict(torch.load(model_save_path + model_name + '.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8648785-577f-4403-b4d8-e6cbd1431954",
   "metadata": {},
   "source": [
    "#recompute the validation using only the best performing model \n",
    "#(hopefully the following steps may be replaced by a testing dataset)\n",
    "\n",
    "val_correct = 0.\n",
    "val_seen = 0.\n",
    "\n",
    "for i, data in enumerate(matrix_maker, 0):##dataloaders['val'], 0):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    bs, c, h, w = inputs.shape\n",
    "    if c == 1:\n",
    "        inputs = inputs.repeat(1, 3, 1, 1).float()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    val_correct += (outputs.argmax(dim=1) == labels).float().sum()\n",
    "    val_seen += len(labels)\n",
    "    \n",
    "    #save targets, predictions, and outputs for analysis\n",
    "    if i==0:\n",
    "        outputs_total = outputs\n",
    "        #preds_total = outputs.argmax(dim=1)\n",
    "        labels_total = labels\n",
    "    else:\n",
    "        outputs_total = torch.cat((outputs_total, outputs), dim=0)\n",
    "        #preds_total = torch.cat((preds_total, outputs.argmax(dim=1)), dim=0)\n",
    "        labels_total = torch.cat((labels_total, labels), dim=0)\n",
    "\n",
    "preds_total = outputs_total.argmax(dim=1)        \n",
    "        \n",
    "#verify sizes\n",
    "print(outputs_total.shape)\n",
    "print(preds_total.shape)\n",
    "print(labels_total.shape)\n",
    "\n",
    "#outputs_total = outputs_total.cpu().detach().numpy()\n",
    "preds_total = preds_total.cpu().detach().numpy()\n",
    "labels_total = labels_total.cpu().detach().numpy()\n",
    "\n",
    "print('The accuracy on the validation set is: %.4f' % (val_correct/val_seen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d6bd54-4c0d-4d42-837d-0b3abe0d3bc0",
   "metadata": {},
   "source": [
    "#confusion matrix on validation data\n",
    "\n",
    "def plot_confusion_matrix(labels, pred_labels, classes):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = confusion_matrix(labels, pred_labels)\n",
    "    cm = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
    "    cm.plot(values_format='d', cmap='Blues', ax=ax)\n",
    "    plt.grid(False)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "plot_confusion_matrix(labels_total, preds_total, class_names)\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_model + '/confusionmatrix_validmat.png')\n",
    "\n",
    "#will need this to compute loss term\n",
    "df_cm = pd.DataFrame(confusion_matrix(labels_total,preds_total))\n",
    "df_cm.to_csv(results_model + '/confusionmatrix_validmat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe76a7e5-1cf8-4a3a-8939-26d3e76230cc",
   "metadata": {},
   "source": [
    "del outputs_total \n",
    "#del preds_total\n",
    "del labels_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e5cebf-dd90-4916-9608-fe3ff32ad83a",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71021ee9-236e-4b4e-bdc0-0bc537a72813",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute test using only the best performing model \n",
    "#(hopefully the following steps may be replaced by a testing dataset)\n",
    "\n",
    "test_correct = 0.\n",
    "test_seen = 0.\n",
    "#rcrm_metric_total = 0.\n",
    "num_batches = 0.\n",
    "\n",
    "for i, data in enumerate(test_loader, 0):##dataloaders['val'], 0):\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    bs, c, h, w = inputs.shape\n",
    "    #print(inputs.shape)\n",
    "    if c == 1:\n",
    "        inputs = inputs.repeat(1, 3, 1, 1).float()\n",
    "\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    test_correct += (outputs.argmax(dim=1) == labels).float().sum()\n",
    "    test_seen += len(labels)\n",
    "    \n",
    "    # Calculate RCR-M metric\n",
    "    #rcrm_metric = RCRMMetric().calculate_rcr_metric(model = model, data = torch.Tensor(inputs).cuda(), target = torch.Tensor(labels).cuda(), num_components=3)\n",
    "    #print(f\"RCR Metric: {rcrm_metric}\")\n",
    "    #rcrm_metric_total += rcrm_metric\n",
    "    \n",
    "    #save targets, predictions, and outputs for analysis\n",
    "    if i==0:\n",
    "        outputs_total = outputs.cpu().detach().numpy()\n",
    "        #preds_total = outputs.argmax(dim=1)\n",
    "        labels_total = labels.cpu().detach().numpy()\n",
    "        inputs_total = inputs.cpu().detach().numpy()\n",
    "    else:\n",
    "        outputs_total = np.concatenate((outputs_total, outputs.cpu().detach().numpy()), axis=0)\n",
    "        #preds_total = torch.cat((preds_total, outputs.argmax(dim=1)), dim=0)\n",
    "        labels_total = np.concatenate((labels_total, labels.cpu().detach().numpy()), axis=0)\n",
    "        inputs_total = np.concatenate((inputs_total, inputs.cpu().detach().numpy()), axis=0)\n",
    "        \n",
    "    num_batches += 1\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    #print(i)\n",
    "    \n",
    "    #if i > 945:\n",
    "    #    break\n",
    "\n",
    "preds_total = torch.Tensor(outputs_total).argmax(dim=1)\n",
    "\n",
    "#rcrm_metric_total = rcrm_metric_total / num_batches\n",
    "rcrm_metric = RCRMMetric().calculate_rcr_metric(model = model, data = torch.Tensor(inputs_total).cuda(), target = torch.Tensor(labels_total).cuda(), num_components=1)\n",
    "print(f\"RCR Metric: {rcrm_metric}\")\n",
    "        \n",
    "#verify sizes\n",
    "print(outputs_total.shape)\n",
    "print(preds_total.shape)\n",
    "print(labels_total.shape)\n",
    "\n",
    "#outputs_total = outputs_total.cpu().detach().numpy()\n",
    "preds_total = preds_total.cpu().detach().numpy()\n",
    "#labels_total = labels_total.cpu().detach().numpy()\n",
    "\n",
    "print('The accuracy on the testing set is: %.4f' % (test_correct/test_seen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424d31a-7d52-4ee6-91ff-f2b4767ad9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix on test data\n",
    "\n",
    "def plot_confusion_matrix(labels, pred_labels, classes):\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    cm = confusion_matrix(labels, pred_labels)\n",
    "    cm = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
    "    cm.plot(values_format='d', cmap='Blues', ax=ax)\n",
    "    plt.grid(False)\n",
    "    plt.xticks(rotation=90)\n",
    "\n",
    "plot_confusion_matrix(labels_total, preds_total, class_names)\n",
    "plt.tight_layout()\n",
    "plt.savefig(results_model + '/confusionmatrix_test.png')\n",
    "\n",
    "#will need this to compute loss term\n",
    "df_cm = pd.DataFrame(confusion_matrix(labels_total,preds_total))\n",
    "df_cm.to_csv(results_model + '/confusionmatrix_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0fc96-1019-4bb1-8c8c-9f7f54d69461",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report on test data\n",
    "\n",
    "report =  classification_report(labels_total, preds_total, target_names = class_names, output_dict = True)\n",
    "print(classification_report(labels_total, preds_total, target_names = class_names))\n",
    "\n",
    "df = pd.DataFrame(report).transpose()\n",
    "df.to_csv(results_model + '/classificationreport.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9a963-5ba7-4ccc-807e-2cad35ed2555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RCR-G metric\n",
    "rcrg_metric = RCRGMetric().calculate_rcr_metric(output = torch.Tensor(outputs_total).cuda(), target = torch.Tensor(preds_total).cuda())\n",
    "print(f\"RCR Metric: {rcrg_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab124a-777b-441b-92fb-5566b81ef2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibration metrics need output softmax\n",
    "\n",
    "m = nn.Softmax(dim=1)\n",
    "outputs_total = m(torch.Tensor(outputs_total))\n",
    "outputs_total = outputs_total.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e0052b-df50-4db9-9f02-cc1e8261c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")\n",
    "\n",
    "plt.rc(\"font\", size=12)\n",
    "plt.rc(\"axes\", labelsize=12)\n",
    "plt.rc(\"xtick\", labelsize=12)\n",
    "plt.rc(\"ytick\", labelsize=12)\n",
    "plt.rc(\"legend\", fontsize=12)\n",
    "\n",
    "plt.rc(\"axes\", titlesize=16)\n",
    "plt.rc(\"figure\", titlesize=16)\n",
    "title = \"Total Calibration Curve\"\n",
    "\n",
    "output_conf = np.max(outputs_total, axis=1)\n",
    "\n",
    "fig = reliability_diagram(labels_total, preds_total, output_conf, num_bins=10, draw_ece=True,\n",
    "                          draw_bin_importance=\"alpha\", draw_averages=True,\n",
    "                          title=title, figsize=(6, 6), dpi=100, \n",
    "                          return_fig=True)\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(results_model + '/' + 'allclass_calibrationcurve' + '.pdf')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374abc9a-a4dc-4fe2-b55d-44a11b819ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibration curves and Brier Loss\n",
    "\n",
    "for i in range(len(class_names)):\n",
    "    \n",
    "    labels_binary = np.zeros(len(labels_total))\n",
    "    labels_binary[np.where(labels_total == i)] = 1\n",
    "    #current_label = class_names[i]\n",
    "    \n",
    "    prob_true, prob_pred = calibration_curve(labels_binary, outputs_total[:,i], n_bins=10, strategy = 'quantile')\n",
    "    \n",
    "    #print('prob_true:')\n",
    "    #print(prob_true)\n",
    "    \n",
    "    #print('prob_pred:')\n",
    "    #print(prob_pred)\n",
    "    \n",
    "    clf_score = brier_score_loss(labels_binary, outputs_total[:,i], pos_label=1)\n",
    "    clf_score = np.round(clf_score,3)\n",
    "    \n",
    "    # Plot perfectly calibrated\n",
    "    plt.plot([0, 1], [0, 1], linestyle = '--', label = 'Ideally Calibrated')# + str(Standard))\n",
    "\n",
    "    # Plot model's calibration curve\n",
    "    plt.plot(prob_pred, prob_true, marker = '.', label = 'Baseline Model')\n",
    "    leg = plt.legend(loc = 'upper left')\n",
    "    plt.xlabel('Average Predicted Probability in each bin')\n",
    "    plt.ylabel('Ratio of positives')\n",
    "    plt.title('Calibration Curve for ' + class_names[i] + ' with Brier Loss: ' + str(clf_score))\n",
    "    plt.savefig(results_model + '/Calibration-Curve_Class-' + class_names[i] + '.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    #Plot all Confidence scores for this class\n",
    "    plt.hist(outputs_total[:,i])\n",
    "    plt.title('Full Histogram for ' + class_names[i])\n",
    "    plt.savefig(results_model + '/Histogram_Full_Class-' + class_names[i] + '.pdf')\n",
    "    plt.close()\n",
    "    \n",
    "    #Plot only Confidence scores for this class in which this was the correct class\n",
    "    outputs_total_pos = np.delete(outputs_total[:,i], np.where(labels_binary == 0))\n",
    "    plt.hist(outputs_total_pos)\n",
    "    plt.title('Positive only Histogram for ' + class_names[i])\n",
    "    plt.savefig(results_model + '/Histogram_Pos_Class-' + class_names[i] + '.pdf')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39638fc2-6fbf-4f96-93db-ef95d946d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#other calibration scores\n",
    "\n",
    "o = torch.Tensor(outputs_total)\n",
    "l = torch.Tensor(labels_total)\n",
    "\n",
    "metric1 = MulticlassCalibrationError(num_classes=len(class_names), n_bins=10, norm='l1')\n",
    "ECE = metric1(o,l)\n",
    "metric2 = MulticlassCalibrationError(num_classes=len(class_names), n_bins=10, norm='l2')\n",
    "RMSCE = metric2(o,l)\n",
    "metric3 = MulticlassCalibrationError(num_classes=len(class_names), n_bins=10, norm='max')\n",
    "MCE = metric3(o,l)\n",
    "\n",
    "print('ECE: %.4f' % (ECE))\n",
    "print('RMSCE: %.4f' % (RMSCE))\n",
    "print('MCE: %.4f' % (MCE))\n",
    "\n",
    "#will need this to compute loss term\n",
    "data = [['ECE', ECE], ['RMSCE', RMSCE], ['MCE', MCE]]\n",
    "df_calmet = pd.DataFrame(data=data, columns=['Metric', 'Value'])\n",
    "df_calmet.to_csv(results_model + '/calibrationmetrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2290d5ec-a956-4a2f-8c41-3295fd4fe75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef751fe-f3cb-4f53-8f69-18747c487a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
